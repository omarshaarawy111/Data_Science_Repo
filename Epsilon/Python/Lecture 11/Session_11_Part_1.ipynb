{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86f63c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!doctype html>\\n<html lang=\"en\" dir=\"ltr\" class=\"plugin-pages plugin-id-default\">\\n<head>\\n<meta charset=\"UTF-8\">\\n<meta name=\"generator\" content=\"Docusaurus v2.2.0\">\\n<title data-rh=\"true\">ScrapeOps - The DevOps Tool For Web Scraping. | ScrapeOps</title><meta data-rh=\"true\" name=\"viewport\" content=\"width=device-width,initial-scale=1\"><meta data-rh=\"true\" name=\"twitter:card\" content=\"summary_large_image\"><meta data-rh=\"true\" property=\"og:url\" content=\"https://scrapeops.io/\"><meta data-rh=\"true\" name=\"docusaurus_locale\" content=\"en\"><meta data-rh=\"true\" name=\"docusaurus_tag\" content=\"default\"><meta data-rh=\"true\" name=\"docsearch:language\" content=\"en\"><meta data-rh=\"true\" name=\"docsearch:docusaurus_tag\" content=\"default\"><meta data-rh=\"true\" name=\"robots\" content=\"max-image-preview:large\"><meta data-rh=\"true\" property=\"og:title\" content=\"ScrapeOps - The DevOps Tool For Web Scraping. | ScrapeOps\"><meta data-rh=\"true\" name=\"description\" content=\"ScrapeOps is a devops tool for web scraping which enables you to easily monitor, analyse and schedule your scraping jobs.\"><meta data-rh=\"true\" property=\"og:description\" content=\"ScrapeOps is a devops tool for web scraping which enables you to easily monitor, analyse and schedule your scraping jobs.\"><link data-rh=\"true\" rel=\"icon\" href=\"/img/favicon.svg\"><link data-rh=\"true\" rel=\"canonical\" href=\"https://scrapeops.io/\"><link data-rh=\"true\" rel=\"alternate\" href=\"https://scrapeops.io/\" hreflang=\"en\"><link data-rh=\"true\" rel=\"alternate\" href=\"https://scrapeops.io/\" hreflang=\"x-default\"><script data-rh=\"true\">function maybeInsertBanner(){window.__DOCUSAURUS_INSERT_BASEURL_BANNER&&insertBanner()}function insertBanner(){var n=document.getElementById(\"docusaurus-base-url-issue-banner-container\");if(n){n.innerHTML=\\'\\\\n<div id=\"docusaurus-base-url-issue-banner\" style=\"border: thick solid red; background-color: rgb(255, 230, 179); margin: 20px; padding: 20px; font-size: 20px;\">\\\\n   <p style=\"font-weight: bold; font-size: 30px;\">Your Docusaurus site did not load properly.</p>\\\\n   <p>A very common reason is a wrong site <a href=\"https://docusaurus.io/docs/docusaurus.config.js/#baseurl\" style=\"font-weight: bold;\">baseUrl configuration</a>.</p>\\\\n   <p>Current configured baseUrl = <span style=\"font-weight: bold; color: red;\">/</span>  (default value)</p>\\\\n   <p>We suggest trying baseUrl = <span id=\"docusaurus-base-url-issue-banner-suggestion-container\" style=\"font-weight: bold; color: green;\"></span></p>\\\\n</div>\\\\n\\';var e=document.getElementById(\"docusaurus-base-url-issue-banner-suggestion-container\"),s=window.location.pathname,r=\"/\"===s.substr(-1)?s:s+\"/\";e.innerHTML=r}}window.__DOCUSAURUS_INSERT_BASEURL_BANNER=!0,document.addEventListener(\"DOMContentLoaded\",maybeInsertBanner)</script><link rel=\"alternate\" type=\"application/rss+xml\" href=\"/blog/rss.xml\" title=\"ScrapeOps RSS Feed\">\\n<link rel=\"alternate\" type=\"application/atom+xml\" href=\"/blog/atom.xml\" title=\"ScrapeOps Atom Feed\">\\n\\n<link rel=\"preconnect\" href=\"https://www.google-analytics.com\">\\n<link rel=\"preconnect\" href=\"https://www.googletagmanager.com\">\\n<script async src=\"https://www.googletagmanager.com/gtag/js?id=G-QJSW9S9YH4\"></script>\\n<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag(\"js\",new Date),gtag(\"config\",\"G-QJSW9S9YH4\",{anonymize_ip:!0})</script>\\n\\n\\n\\n\\n<link rel=\"search\" type=\"application/opensearchdescription+xml\" title=\"ScrapeOps\" href=\"/opensearch.xml\">\\n<script src=\"/get-refferer.js\"></script><link rel=\"stylesheet\" href=\"/assets/css/styles.cd47c9f9.css\">\\n<link rel=\"preload\" href=\"/assets/js/runtime~main.f3a3342d.js\" as=\"script\">\\n<link rel=\"preload\" href=\"/assets/js/main.2a62d07a.js\" as=\"script\">\\n</head>\\n<body class=\"navigation-with-keyboard\">\\n<script>!function(){function t(t){document.documentElement.setAttribute(\"data-theme\",t)}var e=function(){var t=null;try{t=localStorage.getItem(\"theme\")}catch(t){}return t}();t(null!==e?e:\"light\")}(),document.documentElement.setAttribute(\"data-announcement-bar-initially-dismissed\",function(){try{return\"true\"===localStorage.getItem(\"docusaurus.announcement.dismiss\")}catch(t){}return!1}())</script><div id=\"__docusaurus\">\\n<div id=\"docusaurus-base-url-issue-banner-container\"></div><div role=\"region\" aria-label=\"Skip to main content\"><a class=\"skipToContent_fXgn\" href=\"#docusaurus_skipToContent_fallback\">Skip to main content</a></div><div class=\"announcementBar_s0pr\" style=\"background-color:#0d53d7;color:#fff\" role=\"banner\"><div class=\"announcementBarContent_dpRF\">Need a proxy solution? Try ScrapeOps and get <a target=\"_self\" href=\"https://scrapeops.io/app/register/proxy\">1,000 free requests here</a>, or compare all proxy providers <a target=\"_self\" href=\"https://scrapeops.io/proxy-providers/comparison/\">here</a>!</div></div><nav class=\"navbar navbar--fixed-top\"><div class=\"navbar__inner\"><div class=\"navbar__items\"><button aria-label=\"Navigation bar toggle\" class=\"navbar__toggle clean-btn\" type=\"button\" tabindex=\"0\"><svg width=\"30\" height=\"30\" viewBox=\"0 0 30 30\" aria-hidden=\"true\"><path stroke=\"currentColor\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" d=\"M4 7h22M4 15h22M4 23h22\"></path></svg></button><a class=\"navbar__brand\" href=\"/\"><div class=\"navbar__logo\"><img src=\"/img/scrapeops-logo.svg\" alt=\"ScrapeOps Logo\" class=\"themedImage_ToTc themedImage--light_HNdA\"><img src=\"/img/scrapeops-logo.svg\" alt=\"ScrapeOps Logo\" class=\"themedImage_ToTc themedImage--dark_i4oU\"></div><b class=\"navbar__title text--truncate\">ScrapeOps</b></a></div><div class=\"navbar__items navbar__items--right\"><div class=\"navbar__item dropdown dropdown--hoverable dropdown--right\"><a href=\"#\" aria-haspopup=\"true\" aria-expanded=\"false\" role=\"button\" class=\"navbar__link\">Solutions</a><ul class=\"dropdown__menu\"><li><a class=\"dropdown__link\" href=\"/proxy-aggregator/\">Proxy Aggregator</a></li><li><a class=\"dropdown__link\" href=\"/monitoring-scheduling/\">Monitoring &amp; Scheduler</a></li></ul></div><a class=\"navbar__item navbar__link\" href=\"/docs/intro/\">Docs</a><a href=\"https://scrapeops.io/proxy-providers/comparison/\" target=\"_self\" rel=\"noopener noreferrer\" class=\"navbar__item navbar__link\">Proxy Comparison<svg width=\"13.5\" height=\"13.5\" aria-hidden=\"true\" viewBox=\"0 0 24 24\" class=\"iconExternalLink_nPIU\"><path fill=\"currentColor\" d=\"M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z\"></path></svg></a><div class=\"navbar__item dropdown dropdown--hoverable dropdown--right\"><a href=\"#\" aria-haspopup=\"true\" aria-expanded=\"false\" role=\"button\" class=\"navbar__link\">Guides</a><ul class=\"dropdown__menu\"><li><a class=\"dropdown__link\" href=\"/web-scraping-playbook/\">Web Scraping Playbook</a></li><li><a class=\"dropdown__link\" href=\"/python-web-scraping-playbook/\">Python Web Scraping Playbook</a></li><li><a class=\"dropdown__link\" href=\"/python-scrapy-playbook/\">Python Scrapy Playbook</a></li></ul></div><a href=\"https://scrapeops.io/app/login\" target=\"_self\" rel=\"noopener noreferrer\" class=\"navbar__item navbar__link\">Login<svg width=\"13.5\" height=\"13.5\" aria-hidden=\"true\" viewBox=\"0 0 24 24\" class=\"iconExternalLink_nPIU\"><path fill=\"currentColor\" d=\"M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z\"></path></svg></a><a href=\"https://scrapeops.io/app/register/main\" target=\"_self\" rel=\"noopener noreferrer\" class=\"navbar__item navbar__link\">Signup<svg width=\"13.5\" height=\"13.5\" aria-hidden=\"true\" viewBox=\"0 0 24 24\" class=\"iconExternalLink_nPIU\"><path fill=\"currentColor\" d=\"M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z\"></path></svg></a></div></div><div role=\"presentation\" class=\"navbar-sidebar__backdrop\"></div></nav><div class=\"main-wrapper\"><header class=\"hero hero--primary heroBanner_qdFl\"><div class=\"container\" id=\"hero-section\"><h1>Your Complete Toolbox for <br><span class=\"text-brand\"> Web Scraping</span></h1><p id=\"hero-desc\">Schedule your scraping jobs, monitor their performance &amp; scrape with proxies from the ScrapeOps Dashboard.</p><a class=\"link\" href=\"/app/register/main\"><button class=\"button-body button-right-margin brand-button\">Get Free Account</button></a><a class=\"link\" href=\"/app/login/demo\"><button class=\"button-body white-button\">Live Demo</button></a><p id=\"hero-subtext\">Monitor <span class=\"dashed-underline-brand\">unlimited</span> scrapers and pages with our <span class=\"dashed-underline-brand\">free community plan</span>!</p></div></header><div id=\"hero-image-section\"><div id=\"hero-image-holder\"><img class=\"hero-image\" src=\"/img/scrapeops-hero-demo.jpg\" alt=\"ScrapeOps Dashboard Demo\"></div></div><main><div><section><div class=\"container solutions-section\"><div class=\"container\"><div class=\"headerRow__0Vm\"><div class=\"sectionHeader_fDXf medium\"><h2>What Type of Solution Do You Need?</h2></div><div class=\"sectionSubheader_AZk8\"><p>No matter your web scraping requirements are we have got you covered.</p></div></div></div><div class=\"split-section row solutions-row\"><div class=\"col col--4\"><div class=\"solutionRow_tRAe\"><div class=\"solutionHolder_XYLb\"><img src=\"https://assets-scrapeops.nyc3.digitaloceanspaces.com/Icons/scrapeops-proxy-aggregator-icon.svg\" alt=\"ScrapeOps Proxy Aggregator\"><h4>Proxy Aggregator</h4><p>Use over 20+ proxy providers with our all-in-one proxy aggregator. We find the best proxy providers so you don&#x27;t have too.</p><a class=\"link\" href=\"/proxy-aggregator\"><button class=\"button-body brand-button\">Learn More</button></a></div></div></div><div class=\"col col--4\"><div class=\"solutionRow_tRAe\"><div class=\"solutionHolder_XYLb\"><img src=\"https://assets-scrapeops.nyc3.digitaloceanspaces.com/Icons/scrapeops-scheduler-icon.svg\" alt=\"ScrapeOps Job Scheduling\"><h4>Job Scheduling</h4><p>Connect your server with ScrapeOps, deploy code from Github &amp; schedule your spiders from the ScrapeOps dashboard.</p><a class=\"link\" href=\"/monitoring-scheduling\"><button class=\"button-body brand-button\">Learn More</button></a></div></div></div><div class=\"col col--4\"><div class=\"solutionRow_tRAe\"><div class=\"solutionHolder_XYLb\"><img src=\"https://assets-scrapeops.nyc3.digitaloceanspaces.com/Icons/scrapeops-monitoring-icon.svg\" alt=\"ScrapeOps Monitoring &amp; Alerts\"><h4>Monitoring &amp; Alerts</h4><p>Easily monitor your scrapers, log errors, configure health checks, and get alerts from the ScrapeOps dashboard</p><a class=\"link\" href=\"/monitoring-scheduling\"><button class=\"button-body brand-button\">Learn More</button></a></div></div></div></div></div></section></div><section><div class=\"container\"><div class=\"split-section row split-section-row\"><div class=\"col col--6\"><div class=\"textSection_B0uF\"><div class=\"aboveHeader_l9Jr\"><p>ScrapeOps Proxy Aggregator</p></div><div class=\"sectionHeader_f6wS\"><h2>The All-In-One Proxy Solution</h2></div><div class=\"textBlock_nA9o\"><p>Use over +20 proxy providers with our all-in-one proxy aggregator. We find the proxy providers with the best performance &amp; price for every domain so you don&#x27;t have too.</p><p>Never have to worry about rotating a proxy, CAPTCHAs or setting up headless browsers again.</p></div></div><a class=\"link\" href=\"/proxy-aggregator\"><button class=\"button-body brand-button\">Learn More</button></a></div><div class=\"col col--6 proxy-image\"><img src=\"https://assets-scrapeops.nyc3.digitaloceanspaces.com/Images/landing-pages/proxy-aggregator-hero.png\" alt=\"ScrapeOps Proxy Aggregator\"></div></div></div></section><section><div class=\"container\"><div class=\"split-section row split-section-row\"><div class=\"col col--6\"><img src=\"/img/scheduled-jobs-combo.png\" alt=\"ScrapeOps Job Scheduler\"></div><div class=\"col col--6\"><div class=\"textSection_B0uF\"><div class=\"aboveHeader_l9Jr\"><p>Scrapeops Server Manager</p></div><div class=\"sectionHeader_f6wS\"><h2>Simplified Job Scheduling</h2></div><div class=\"textBlock_nA9o\"><p>Connect your servers &amp; Github with ScrapeOps, and manage your web scrapers across multiple servers from one easy to use job management dashboard.</p><p>Deploy, schedule, run, pause and re-run your scraping jobs with our SSH server &amp; Github integration.</p></div></div><a class=\"link\" href=\"/monitoring-scheduling\"><button class=\"button-body brand-button\">Learn More</button></a></div></div></div></section><section><div class=\"container\"><div class=\"split-section row split-section-row\"><div class=\"col col--6\"><div class=\"textSection_B0uF\"><div class=\"aboveHeader_l9Jr\"><p>ScrapeOps Monitoring</p></div><div class=\"sectionHeader_f6wS\"><h2>Real-Time Job Monitoring</h2></div><div class=\"textBlock_nA9o\"><p>Using the ScrapeOps SDK you can easily monitor your scrapers, log errors and get alerts from a single dashboard.</p><p>Effortlessly compare pages &amp; items scraped, runtimes, status codes, success rates and errors versus previous job runs to identify potential issues with your scrapers.</p></div></div><span class=\"button-right-margin\"><a class=\"link\" href=\"/monitoring-scheduling\"><button class=\"button-body brand-button\">Learn More</button></a></span><a class=\"link\" href=\"/app/login/demo\"><button class=\"button-body white-button\">Live Demo</button></a></div><div class=\"col col--6 demo-image\"><img src=\"/img/scrapeops-real-time-monitoring.png\" alt=\"ScrapeOps Real-Time Scraper Monitoring\"></div></div></div></section><div class=\"container\"><div class=\"headerRow__0Vm\"><div class=\"sectionHeader_fDXf undefined\"><h2>Why Use ScrapeOps?</h2></div><div class=\"sectionSubheader_AZk8\"><p>If web scraped data is mission critical for your business, then ScrapeOps has the features to make your life a whole lot easier.</p></div></div></div><section><div class=\"container\"><div class=\"benefitsSection_BBv3\"><div class=\"row\"><div class=\"undefined col col--4\"><div class=\"benefitsRow_GJdx\"><div class=\"benefitsHolder_CwJp\"><svg class=\"checkmark\" width=\"30\" height=\"30\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"outer-circle\" d=\"M12 24C18.6274 24 24 18.6274 24 12C24 5.37258 18.6274 0 12 0C5.37258 0 0 5.37258 0 12C0 18.6274 5.37258 24 12 24Z\"></path><path class=\"brand2-tick\" d=\"M15.7845 7.97542L10.353 13.5681L8.89179 11.818C8.24764 11.2582 7.23472 11.9105 7.69527 12.7493L9.43186 15.8047C9.70729 16.1778 10.353 16.5502 10.9971 15.8047C11.2725 15.4315 16.5205 8.81347 16.5205 8.81347C17.1654 8.06795 16.3369 7.41572 15.7845 7.97467V7.97542Z\"></path></svg></div><div class=\"benefitsHolder_CwJp\"><h4>Real-Time &amp; Historical Job Stats</h4><p>Easily monitor jobs in real-time, compare jobs to previous jobs run, spot trends forming and catch problems early before your data feeds go down.</p></div></div></div><div class=\"undefined col col--4\"><div class=\"benefitsRow_GJdx\"><div class=\"benefitsHolder_CwJp\"><svg class=\"checkmark\" width=\"30\" height=\"30\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"outer-circle\" d=\"M12 24C18.6274 24 24 18.6274 24 12C24 5.37258 18.6274 0 12 0C5.37258 0 0 5.37258 0 12C0 18.6274 5.37258 24 12 24Z\"></path><path class=\"brand2-tick\" d=\"M15.7845 7.97542L10.353 13.5681L8.89179 11.818C8.24764 11.2582 7.23472 11.9105 7.69527 12.7493L9.43186 15.8047C9.70729 16.1778 10.353 16.5502 10.9971 15.8047C11.2725 15.4315 16.5205 8.81347 16.5205 8.81347C17.1654 8.06795 16.3369 7.41572 15.7845 7.97467V7.97542Z\"></path></svg></div><div class=\"benefitsHolder_CwJp\"><h4>Item &amp; Page Vaildation</h4><p>ScrapeOps checks pages for CAPTCHAs &amp; bans, and the data quality of every item scraped so you can detect broken parsers without having to query your DB.</p></div></div></div><div class=\"undefined col col--4\"><div class=\"benefitsRow_GJdx\"><div class=\"benefitsHolder_CwJp\"><svg class=\"checkmark\" width=\"30\" height=\"30\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"outer-circle\" d=\"M12 24C18.6274 24 24 18.6274 24 12C24 5.37258 18.6274 0 12 0C5.37258 0 0 5.37258 0 12C0 18.6274 5.37258 24 12 24Z\"></path><path class=\"brand2-tick\" d=\"M15.7845 7.97542L10.353 13.5681L8.89179 11.818C8.24764 11.2582 7.23472 11.9105 7.69527 12.7493L9.43186 15.8047C9.70729 16.1778 10.353 16.5502 10.9971 15.8047C11.2725 15.4315 16.5205 8.81347 16.5205 8.81347C17.1654 8.06795 16.3369 7.41572 15.7845 7.97467V7.97542Z\"></path></svg></div><div class=\"benefitsHolder_CwJp\"><h4>Error Monitoring</h4><p>The ScrapeOps SDK logs any Warnings or Errors raised in your jobs and aggregates them on your dashboard, so you can see your errors without having to check your logs.</p></div></div></div></div><div class=\"row\"><div class=\"undefined col col--4\"><div class=\"benefitsRow_GJdx\"><div class=\"benefitsHolder_CwJp\"><svg class=\"checkmark\" width=\"30\" height=\"30\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"outer-circle\" d=\"M12 24C18.6274 24 24 18.6274 24 12C24 5.37258 18.6274 0 12 0C5.37258 0 0 5.37258 0 12C0 18.6274 5.37258 24 12 24Z\"></path><path class=\"brand2-tick\" d=\"M15.7845 7.97542L10.353 13.5681L8.89179 11.818C8.24764 11.2582 7.23472 11.9105 7.69527 12.7493L9.43186 15.8047C9.70729 16.1778 10.353 16.5502 10.9971 15.8047C11.2725 15.4315 16.5205 8.81347 16.5205 8.81347C17.1654 8.06795 16.3369 7.41572 15.7845 7.97467V7.97542Z\"></path></svg></div><div class=\"benefitsHolder_CwJp\"><h4>Server Provisioning</h4><p>Directly link your hosting provider with ScrapeOps, then provision and setup new servers from the ScrapeOps dashboard.</p></div></div></div><div class=\"undefined col col--4\"><div class=\"benefitsRow_GJdx\"><div class=\"benefitsHolder_CwJp\"><svg class=\"checkmark\" width=\"30\" height=\"30\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"outer-circle\" d=\"M12 24C18.6274 24 24 18.6274 24 12C24 5.37258 18.6274 0 12 0C5.37258 0 0 5.37258 0 12C0 18.6274 5.37258 24 12 24Z\"></path><path class=\"brand2-tick\" d=\"M15.7845 7.97542L10.353 13.5681L8.89179 11.818C8.24764 11.2582 7.23472 11.9105 7.69527 12.7493L9.43186 15.8047C9.70729 16.1778 10.353 16.5502 10.9971 15.8047C11.2725 15.4315 16.5205 8.81347 16.5205 8.81347C17.1654 8.06795 16.3369 7.41572 15.7845 7.97467V7.97542Z\"></path></svg></div><div class=\"benefitsHolder_CwJp\"><h4>Job Scheduling</h4><p>Give ScrapeOps SSH access to your servers, and you will be able to schedule and run any type of scraper from the dashboard.</p></div></div></div><div class=\"undefined col col--4\"><div class=\"benefitsRow_GJdx\"><div class=\"benefitsHolder_CwJp\"><svg class=\"checkmark\" width=\"30\" height=\"30\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"outer-circle\" d=\"M12 24C18.6274 24 24 18.6274 24 12C24 5.37258 18.6274 0 12 0C5.37258 0 0 5.37258 0 12C0 18.6274 5.37258 24 12 24Z\"></path><path class=\"brand2-tick\" d=\"M15.7845 7.97542L10.353 13.5681L8.89179 11.818C8.24764 11.2582 7.23472 11.9105 7.69527 12.7493L9.43186 15.8047C9.70729 16.1778 10.353 16.5502 10.9971 15.8047C11.2725 15.4315 16.5205 8.81347 16.5205 8.81347C17.1654 8.06795 16.3369 7.41572 15.7845 7.97467V7.97542Z\"></path></svg></div><div class=\"benefitsHolder_CwJp\"><h4>Code Deployment</h4><p>Link your Github repos to ScrapeOps and deploy new scrapers to your servers directly from the ScrapeOps dashboard.</p></div></div></div></div><div class=\"row\"><div class=\"undefined col col--4\"><div class=\"benefitsRow_GJdx\"><div class=\"benefitsHolder_CwJp\"><svg class=\"checkmark\" width=\"30\" height=\"30\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"outer-circle\" d=\"M12 24C18.6274 24 24 18.6274 24 12C24 5.37258 18.6274 0 12 0C5.37258 0 0 5.37258 0 12C0 18.6274 5.37258 24 12 24Z\"></path><path class=\"brand2-tick\" d=\"M15.7845 7.97542L10.353 13.5681L8.89179 11.818C8.24764 11.2582 7.23472 11.9105 7.69527 12.7493L9.43186 15.8047C9.70729 16.1778 10.353 16.5502 10.9971 15.8047C11.2725 15.4315 16.5205 8.81347 16.5205 8.81347C17.1654 8.06795 16.3369 7.41572 15.7845 7.97467V7.97542Z\"></path></svg></div><div class=\"benefitsHolder_CwJp\"><h4>Custom Health Checks &amp; Alerts</h4><p>Create custom real-time scraper health checks for all your scrapers so you detect unhealthy jobs straight away.</p></div></div></div><div class=\"undefined col col--4\"><div class=\"benefitsRow_GJdx\"><div class=\"benefitsHolder_CwJp\"><svg class=\"checkmark\" width=\"30\" height=\"30\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"outer-circle\" d=\"M12 24C18.6274 24 24 18.6274 24 12C24 5.37258 18.6274 0 12 0C5.37258 0 0 5.37258 0 12C0 18.6274 5.37258 24 12 24Z\"></path><path class=\"brand2-tick\" d=\"M15.7845 7.97542L10.353 13.5681L8.89179 11.818C8.24764 11.2582 7.23472 11.9105 7.69527 12.7493L9.43186 15.8047C9.70729 16.1778 10.353 16.5502 10.9971 15.8047C11.2725 15.4315 16.5205 8.81347 16.5205 8.81347C17.1654 8.06795 16.3369 7.41572 15.7845 7.97467V7.97542Z\"></path></svg></div><div class=\"benefitsHolder_CwJp\"><h4>Custom Periodic Reports</h4><p>Automate your daily scraping checks by scheduling ScrapeOps to check your spiders &amp; jobs every couple hours and send you a report if any issues are detected.</p></div></div></div><div class=\"undefined col col--4\"><div class=\"benefitsRow_GJdx\"><div class=\"benefitsHolder_CwJp\"><svg class=\"checkmark\" width=\"30\" height=\"30\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\"><path class=\"outer-circle\" d=\"M12 24C18.6274 24 24 18.6274 24 12C24 5.37258 18.6274 0 12 0C5.37258 0 0 5.37258 0 12C0 18.6274 5.37258 24 12 24Z\"></path><path class=\"brand2-tick\" d=\"M15.7845 7.97542L10.353 13.5681L8.89179 11.818C8.24764 11.2582 7.23472 11.9105 7.69527 12.7493L9.43186 15.8047C9.70729 16.1778 10.353 16.5502 10.9971 15.8047C11.2725 15.4315 16.5205 8.81347 16.5205 8.81347C17.1654 8.06795 16.3369 7.41572 15.7845 7.97467V7.97542Z\"></path></svg></div><div class=\"benefitsHolder_CwJp\"><h4>Proxy Aggregator</h4><p>Never have to worry about finding proxy providers, rotatings IPs, dealing with CAPTCHAs or bans again when you use our All-In-One Proxy Aggregator.</p></div></div></div></div><div class=\"row\"></div></div></div></section><div class=\"grey-section\"><section><div class=\"container\"><div class=\"row bannerSection_odgg\"><div class=\"col col--8 textSection_t3Ym\"><h3>Ready to make web scraping less painful?</h3><h3 class=\"brandColor_Ydux\">Sign up for a free account today.</h3></div><div class=\"col col--4 buttonSection_XsN2\"><a class=\"link\" href=\"/app/register/main\"><button class=\"button-body brand-button button-right-margin\">Get Free Account</button></a><a class=\"link\" href=\"/app/login/demo\"><button class=\"button-body white-button\">Live Demo</button></a></div></div></div></section></div></main></div><footer class=\"footer footer--dark\"><div class=\"container container-fluid\"><div class=\"row footer__links\"><div class=\"col footer__col\"><div class=\"footer__title\">About us</div><ul class=\"footer__items clean-list\"><li class=\"footer__item\">ScrapeOps exists to improve & add transparency to the world of scraping.</li></ul></div><div class=\"col footer__col\"><div class=\"footer__title\">Resources</div><ul class=\"footer__items clean-list\"><li class=\"footer__item\"><a href=\"https://scrapeops.io/proxy-providers/comparison/\" target=\"_blank\" rel=\"noopener noreferrer\" class=\"footer__link-item\">Proxy Comparison Tool</a></li><li class=\"footer__item\"><a class=\"footer__link-item\" href=\"/web-scraping-playbook/\">Web Scraping Playbook</a></li><li class=\"footer__item\"><a class=\"footer__link-item\" href=\"/python-web-scraping-playbook/\">Python Web Scraping Playbook</a></li><li class=\"footer__item\"><a class=\"footer__link-item\" href=\"/python-scrapy-playbook/\">Python Scrapy Playbook</a></li><li class=\"footer__item\"><a class=\"footer__link-item\" href=\"/docs/intro/\">Documentation</a></li><li class=\"footer__item\"><a class=\"footer__link-item\" href=\"/blog/\">Blog</a></li><li class=\"footer__item\"><a href=\"https://github.com/ScrapeOps\" target=\"_blank\" rel=\"noopener noreferrer\" class=\"footer__link-item\">GitHub</a></li></ul></div><div class=\"col footer__col\"><div class=\"footer__title\">Company</div><ul class=\"footer__items clean-list\"><li class=\"footer__item\"><a class=\"footer__link-item\" href=\"/privacy-policy/\">Privacy Policy</a></li><li class=\"footer__item\"><a class=\"footer__link-item\" href=\"/terms-of-service/\">Terms Of Service</a></li><li class=\"footer__item\"><a class=\"footer__link-item\" href=\"/data-protection-policy/\">Data Protection Policy</a></li></ul></div></div><div class=\"footer__bottom text--center\"><div class=\"footer__copyright\">Copyright \\xc2\\xa9 2023 ScrapeOps.</div></div></div></footer></div>\\n<script src=\"/assets/js/runtime~main.f3a3342d.js\"></script>\\n<script src=\"/assets/js/main.2a62d07a.js\"></script>\\n</body>\\n</html>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://scrapeops.io'\n",
    "response=requests.get(url)\n",
    "response\n",
    "response.text\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43f2d028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"skipToContent_fXgn\" href=\"#docusaurus_skipToContent_fallback\">Skip to main content</a>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "soup\n",
    "\n",
    "link=soup.find('a')\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d6afa38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"skipToContent_fXgn\" href=\"#docusaurus_skipToContent_fallback\">Skip to main content</a>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link=soup.find('a',attrs={'class':'skipToContent_fXgn'})\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f153d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"skipToContent_fXgn\" href=\"#docusaurus_skipToContent_fallback\">Skip to main content</a>,\n",
       " <a href=\"https://scrapeops.io/app/register/proxy\" target=\"_self\">1,000 free requests here</a>,\n",
       " <a href=\"https://scrapeops.io/proxy-providers/comparison/\" target=\"_self\">here</a>,\n",
       " <a class=\"navbar__brand\" href=\"/\"><div class=\"navbar__logo\"><img alt=\"ScrapeOps Logo\" class=\"themedImage_ToTc themedImage--light_HNdA\" src=\"/img/scrapeops-logo.svg\"/><img alt=\"ScrapeOps Logo\" class=\"themedImage_ToTc themedImage--dark_i4oU\" src=\"/img/scrapeops-logo.svg\"/></div><b class=\"navbar__title text--truncate\">ScrapeOps</b></a>,\n",
       " <a aria-expanded=\"false\" aria-haspopup=\"true\" class=\"navbar__link\" href=\"#\" role=\"button\">Solutions</a>,\n",
       " <a class=\"dropdown__link\" href=\"/proxy-aggregator/\">Proxy Aggregator</a>,\n",
       " <a class=\"dropdown__link\" href=\"/monitoring-scheduling/\">Monitoring &amp; Scheduler</a>,\n",
       " <a class=\"navbar__item navbar__link\" href=\"/docs/intro/\">Docs</a>,\n",
       " <a class=\"navbar__item navbar__link\" href=\"https://scrapeops.io/proxy-providers/comparison/\" rel=\"noopener noreferrer\" target=\"_self\">Proxy Comparison<svg aria-hidden=\"true\" class=\"iconExternalLink_nPIU\" height=\"13.5\" viewbox=\"0 0 24 24\" width=\"13.5\"><path d=\"M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z\" fill=\"currentColor\"></path></svg></a>,\n",
       " <a aria-expanded=\"false\" aria-haspopup=\"true\" class=\"navbar__link\" href=\"#\" role=\"button\">Guides</a>,\n",
       " <a class=\"dropdown__link\" href=\"/web-scraping-playbook/\">Web Scraping Playbook</a>,\n",
       " <a class=\"dropdown__link\" href=\"/python-web-scraping-playbook/\">Python Web Scraping Playbook</a>,\n",
       " <a class=\"dropdown__link\" href=\"/python-scrapy-playbook/\">Python Scrapy Playbook</a>,\n",
       " <a class=\"navbar__item navbar__link\" href=\"https://scrapeops.io/app/login\" rel=\"noopener noreferrer\" target=\"_self\">Login<svg aria-hidden=\"true\" class=\"iconExternalLink_nPIU\" height=\"13.5\" viewbox=\"0 0 24 24\" width=\"13.5\"><path d=\"M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z\" fill=\"currentColor\"></path></svg></a>,\n",
       " <a class=\"navbar__item navbar__link\" href=\"https://scrapeops.io/app/register/main\" rel=\"noopener noreferrer\" target=\"_self\">Signup<svg aria-hidden=\"true\" class=\"iconExternalLink_nPIU\" height=\"13.5\" viewbox=\"0 0 24 24\" width=\"13.5\"><path d=\"M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z\" fill=\"currentColor\"></path></svg></a>,\n",
       " <a class=\"link\" href=\"/app/register/main\"><button class=\"button-body button-right-margin brand-button\">Get Free Account</button></a>,\n",
       " <a class=\"link\" href=\"/app/login/demo\"><button class=\"button-body white-button\">Live Demo</button></a>,\n",
       " <a class=\"link\" href=\"/proxy-aggregator\"><button class=\"button-body brand-button\">Learn More</button></a>,\n",
       " <a class=\"link\" href=\"/monitoring-scheduling\"><button class=\"button-body brand-button\">Learn More</button></a>,\n",
       " <a class=\"link\" href=\"/monitoring-scheduling\"><button class=\"button-body brand-button\">Learn More</button></a>,\n",
       " <a class=\"link\" href=\"/proxy-aggregator\"><button class=\"button-body brand-button\">Learn More</button></a>,\n",
       " <a class=\"link\" href=\"/monitoring-scheduling\"><button class=\"button-body brand-button\">Learn More</button></a>,\n",
       " <a class=\"link\" href=\"/monitoring-scheduling\"><button class=\"button-body brand-button\">Learn More</button></a>,\n",
       " <a class=\"link\" href=\"/app/login/demo\"><button class=\"button-body white-button\">Live Demo</button></a>,\n",
       " <a class=\"link\" href=\"/app/register/main\"><button class=\"button-body brand-button button-right-margin\">Get Free Account</button></a>,\n",
       " <a class=\"link\" href=\"/app/login/demo\"><button class=\"button-body white-button\">Live Demo</button></a>,\n",
       " <a class=\"footer__link-item\" href=\"https://scrapeops.io/proxy-providers/comparison/\" rel=\"noopener noreferrer\" target=\"_blank\">Proxy Comparison Tool</a>,\n",
       " <a class=\"footer__link-item\" href=\"/web-scraping-playbook/\">Web Scraping Playbook</a>,\n",
       " <a class=\"footer__link-item\" href=\"/python-web-scraping-playbook/\">Python Web Scraping Playbook</a>,\n",
       " <a class=\"footer__link-item\" href=\"/python-scrapy-playbook/\">Python Scrapy Playbook</a>,\n",
       " <a class=\"footer__link-item\" href=\"/docs/intro/\">Documentation</a>,\n",
       " <a class=\"footer__link-item\" href=\"/blog/\">Blog</a>,\n",
       " <a class=\"footer__link-item\" href=\"https://github.com/ScrapeOps\" rel=\"noopener noreferrer\" target=\"_blank\">GitHub</a>,\n",
       " <a class=\"footer__link-item\" href=\"/privacy-policy/\">Privacy Policy</a>,\n",
       " <a class=\"footer__link-item\" href=\"/terms-of-service/\">Terms Of Service</a>,\n",
       " <a class=\"footer__link-item\" href=\"/data-protection-policy/\">Data Protection Policy</a>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_all=soup.find_all('a')\n",
    "link_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d74f2b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Proxy Aggregator',\n",
       " 'Monitoring & Scheduler',\n",
       " 'Web Scraping Playbook',\n",
       " 'Python Web Scraping Playbook',\n",
       " 'Python Scrapy Playbook']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_all=soup.find_all('a',attrs={'class':'dropdown__link'})\n",
    "link_all\n",
    "link_all_text=[]\n",
    "for i in range(0,len(link_all)) :\n",
    "    link_all_text.append(link_all[i].get_text())\n",
    "link_all_text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e4f0300",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Skip to main content.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12304\\3946557556.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Skip to main content.csv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75cbf7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link.has_attr('class')\n",
    "link.has_attr('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cb6f8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Skip to main content'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a2e869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_url='https://google.com/robots.txt'\n",
    "local_file=\"D:\\Work\\\\Software\\\\DS\\\\Epsilon\\\\Python\\\\Lecture 11\\\\Codes\\\\Local_file.txt\"\n",
    "data=requests.get(remote_url)\n",
    "with open(local_file,'wb') as file:\n",
    "    file.write(data.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b02217f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wget'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1904\\2693257447.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mwget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mremote_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'https://google.com/robots.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlocal_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"D:\\Work\\\\Software\\\\DS\\\\Epsilon\\\\Python\\\\Lecture 11\\\\Codes\\\\Local_file_1.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremote_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wget'"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "remote_url='https://google.com/robots.txt'\n",
    "local_file=\"D:\\Work\\\\Software\\\\DS\\\\Epsilon\\\\Python\\\\Lecture 11\\\\Codes\\\\Local_file_1.txt\"\n",
    "wget.download(remote_url,local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65784585",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3701d828",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e1f572",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10176\\2966680582.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb01fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
